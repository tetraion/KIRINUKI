#!/usr/bin/env python3
"""
KIRINUKI Processor - ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã²ã‚ã‚†ãå‹•ç”»ã®åˆ‡ã‚ŠæŠœãã«å­—å¹•ã¨ãƒ©ã‚¤ãƒ–ãƒãƒ£ãƒƒãƒˆã‚’é‡ã­ã‚‹ãƒ„ãƒ¼ãƒ«
"""

import os
import sys
import argparse
from pathlib import Path
from typing import Any, Optional

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent))

from kirinuki_processor.steps.step0_config import (
    load_config_from_file,
    create_sample_config,
    ClipConfig
)
from kirinuki_processor.steps.step0_download_clip import download_and_clip_video
from kirinuki_processor.steps.step1_generate_subtitles import (
    generate_subtitles_with_whisper,
    convert_srt_to_ass
)
from kirinuki_processor.steps.step1_5_fix_subtitles import fix_subtitle_file
from kirinuki_processor.steps.step3_fetch_chat import fetch_chat
from kirinuki_processor.steps.step4_extract_chat import load_and_extract_chat
from kirinuki_processor.steps.step5_generate_overlay import (
    generate_overlay_from_file,
    OverlayConfig
)
from kirinuki_processor.steps.step6_compose_video import compose_video
from kirinuki_processor.steps.step_title_bar import generate_title_bar
from kirinuki_processor.steps.step7_generate_description import generate_youtube_description
from kirinuki_processor.utils.video_utils import get_video_duration
from kirinuki_processor.constants import (
    DEFAULT_CROP_CRF,
    DEFAULT_CROP_BITRATE,
    DEFAULT_VIDEO_DURATION_FALLBACK
)
import subprocess
import re
import glob
import shutil

# ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆç‹¬ç«‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼‰
from shorts import generate_short_video


def concatenate_videos(video_paths: list, output_path: str) -> bool:
    """
    è¤‡æ•°ã®å‹•ç”»ã‚’é€£çµã™ã‚‹

    Args:
        video_paths: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ãƒªã‚¹ãƒˆ
        output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        æˆåŠŸã—ãŸå ´åˆTrue
    """
    if len(video_paths) == 1:
        # 1ã¤ã ã‘ã®å ´åˆã¯ã‚³ãƒ”ãƒ¼
        shutil.copy2(video_paths[0], output_path)
        return True

    # FFmpegã®é€£çµãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
    concat_list_path = output_path + ".concat_list.txt"
    try:
        with open(concat_list_path, 'w', encoding='utf-8') as f:
            for video_path in video_paths:
                # çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
                abs_path = os.path.abspath(video_path)
                # ãƒ‘ã‚¹ã«ã‚·ãƒ³ã‚°ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã‚„ã‚¹ãƒšãƒ¼ã‚¹ãŒã‚ã‚‹å ´åˆã®ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†
                escaped_path = abs_path.replace("'", "'\\''")
                f.write(f"file '{escaped_path}'\n")

        # FFmpegã§é€£çµ
        cmd = [
            'ffmpeg', '-y',
            '-f', 'concat',
            '-safe', '0',
            '-i', concat_list_path,
            '-c', 'copy',
            output_path
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0:
            print(f"FFmpeg error: {result.stderr}")
            return False

        return True
    except Exception as e:
        print(f"Error concatenating videos: {e}")
        return False
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        if os.path.exists(concat_list_path):
            os.remove(concat_list_path)


def merge_subtitle_files(subtitle_paths: list, output_path: str) -> bool:
    """
    è¤‡æ•°ã®SRTå­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ™‚é–“ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’è€ƒæ…®ã—ã¦ãƒãƒ¼ã‚¸

    Args:
        subtitle_paths: å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ãƒªã‚¹ãƒˆ
        output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        æˆåŠŸã—ãŸå ´åˆTrue
    """
    try:
        merged_subtitles = []
        subtitle_index = 1
        time_offset = 0.0

        for i, srt_path in enumerate(subtitle_paths):
            if not os.path.exists(srt_path):
                print(f"Warning: Subtitle file not found: {srt_path}")
                continue

            # SRTãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            with open(srt_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # SRTå½¢å¼ã®ã‚¨ãƒ³ãƒˆãƒªã‚’è§£æ
            # ãƒ‘ã‚¿ãƒ¼ãƒ³: ç•ªå·\næ™‚åˆ» --> æ™‚åˆ»\nå­—å¹•ãƒ†ã‚­ã‚¹ãƒˆ
            pattern = r'(\d+)\n(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\n((?:.*\n)*?)(?:\n|$)'
            matches = re.findall(pattern, content)

            for match in matches:
                _, start_time, end_time, text = match

                # æ™‚åˆ»ã‚’ãƒ‘ãƒ¼ã‚¹
                start_ms = parse_srt_time(start_time) + time_offset * 1000
                end_ms = parse_srt_time(end_time) + time_offset * 1000

                # æ–°ã—ã„å­—å¹•ã‚¨ãƒ³ãƒˆãƒªã‚’è¿½åŠ 
                merged_subtitles.append({
                    'index': subtitle_index,
                    'start': format_srt_time(start_ms),
                    'end': format_srt_time(end_ms),
                    'text': text.strip()
                })
                subtitle_index += 1

            # æ¬¡ã®ã‚¯ãƒªãƒƒãƒ—ã®ãŸã‚ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’æ›´æ–°
            # å¯¾å¿œã™ã‚‹å‹•ç”»ã®é•·ã•ã‚’å–å¾—
            # subs_clip.srt -> clip.webm, subs_clip_1.srt -> clip_1.webm
            video_path = srt_path.replace('subs_clip', 'clip').replace('.srt', '.webm')
            if os.path.exists(video_path):
                duration = get_video_duration(video_path)
                time_offset += duration
            else:
                print(f"Warning: Could not find video file for subtitle: {video_path}")
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼ˆå‹•ç”»é•·ã•å–å¾—å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                time_offset += DEFAULT_VIDEO_DURATION_FALLBACK

        # ãƒãƒ¼ã‚¸ã—ãŸå­—å¹•ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        with open(output_path, 'w', encoding='utf-8') as f:
            for sub in merged_subtitles:
                f.write(f"{sub['index']}\n")
                f.write(f"{sub['start']} --> {sub['end']}\n")
                f.write(f"{sub['text']}\n\n")

        return True
    except Exception as e:
        print(f"Error merging subtitles: {e}")
        return False


def parse_srt_time(time_str: str) -> float:
    """SRTæ™‚åˆ»æ–‡å­—åˆ—ã‚’ãƒŸãƒªç§’ã«å¤‰æ›"""
    # 00:00:00,000
    h, m, s_ms = time_str.split(':')
    s, ms = s_ms.split(',')
    return (int(h) * 3600 + int(m) * 60 + int(s)) * 1000 + int(ms)


def format_srt_time(ms: float) -> str:
    """ãƒŸãƒªç§’ã‚’SRTæ™‚åˆ»æ–‡å­—åˆ—ã«å¤‰æ›"""
    ms = int(ms)
    h = ms // 3600000
    ms %= 3600000
    m = ms // 60000
    ms %= 60000
    s = ms // 1000
    ms %= 1000
    return f"{h:02d}:{m:02d}:{s:02d},{ms:03d}"


def merge_ass_overlays(overlay_paths: list, output_path: str, video_paths: list) -> bool:
    """
    è¤‡æ•°ã®ASSå­—å¹•ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’æ™‚é–“ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’è€ƒæ…®ã—ã¦ãƒãƒ¼ã‚¸

    Args:
        overlay_paths: ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ãƒªã‚¹ãƒˆ
        output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        video_paths: å¯¾å¿œã™ã‚‹å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ãƒªã‚¹ãƒˆï¼ˆæ™‚é–“ã‚ªãƒ•ã‚»ãƒƒãƒˆè¨ˆç®—ç”¨ï¼‰

    Returns:
        æˆåŠŸã—ãŸå ´åˆTrue
    """
    try:
        # ASSãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã‚¤ãƒ™ãƒ³ãƒˆã‚’åˆ†é›¢ã—ã¦ãƒãƒ¼ã‚¸
        header = None
        all_events = []
        time_offset = 0.0

        for i, ass_path in enumerate(overlay_paths):
            if not os.path.exists(ass_path):
                print(f"Warning: Overlay file not found: {ass_path}")
                continue

            with open(ass_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # [Events]ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã™
            parts = content.split('[Events]')
            if len(parts) != 2:
                continue

            # æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å–å¾—
            if header is None:
                header = parts[0] + '[Events]'

            # ã‚¤ãƒ™ãƒ³ãƒˆè¡Œã‚’å–å¾—
            events_section = parts[1]
            event_lines = events_section.strip().split('\n')

            for line in event_lines:
                if line.startswith('Dialogue:'):
                    # Dialogueè¡Œã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’èª¿æ•´
                    adjusted_line = adjust_ass_dialogue_time(line, time_offset)
                    all_events.append(adjusted_line)
                elif line.startswith('Format:'):
                    # Formatã¯æœ€åˆã®1å›ã ã‘
                    if i == 0:
                        all_events.insert(0, line)

            # æ¬¡ã®ã‚¯ãƒªãƒƒãƒ—ã®ãŸã‚ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’æ›´æ–°
            duration = get_video_duration(video_paths[i])
            time_offset += duration

        # ãƒãƒ¼ã‚¸ã—ãŸASSãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã¿
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(header)
            f.write('\n')
            for event in all_events:
                f.write(event + '\n')

        return True
    except Exception as e:
        print(f"Error merging ASS overlays: {e}")
        return False


def adjust_ass_dialogue_time(dialogue_line: str, offset_seconds: float) -> str:
    """
    ASSã®Dialogueè¡Œã®æ™‚åˆ»ã‚’ã‚ªãƒ•ã‚»ãƒƒãƒˆç§’ã ã‘èª¿æ•´

    Args:
        dialogue_line: Dialogueè¡Œ
        offset_seconds: ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼ˆç§’ï¼‰

    Returns:
        èª¿æ•´å¾Œã®Dialogueè¡Œ
    """
    # Dialogue: Layer,Start,End,Style,Name,MarginL,MarginR,MarginV,Effect,Text
    parts = dialogue_line.split(',', 9)
    if len(parts) < 10:
        return dialogue_line

    # Startæ™‚åˆ»ã¨Endæ™‚åˆ»ã‚’èª¿æ•´
    start_time = parts[1]
    end_time = parts[2]

    adjusted_start = adjust_ass_time(start_time, offset_seconds)
    adjusted_end = adjust_ass_time(end_time, offset_seconds)

    parts[1] = adjusted_start
    parts[2] = adjusted_end

    return ','.join(parts)


def adjust_ass_time(time_str: str, offset_seconds: float) -> str:
    """
    ASSæ™‚åˆ»æ–‡å­—åˆ—ã‚’ã‚ªãƒ•ã‚»ãƒƒãƒˆç§’ã ã‘èª¿æ•´

    Args:
        time_str: ASSæ™‚åˆ»æ–‡å­—åˆ—ï¼ˆh:mm:ss.ccå½¢å¼ï¼‰
        offset_seconds: ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼ˆç§’ï¼‰

    Returns:
        èª¿æ•´å¾Œã®æ™‚åˆ»æ–‡å­—åˆ—
    """
    # h:mm:ss.cc ã‚’è§£æ
    match = re.match(r'(\d+):(\d{2}):(\d{2})\.(\d{2})', time_str)
    if not match:
        return time_str

    h, m, s, cs = map(int, match.groups())
    total_seconds = h * 3600 + m * 60 + s + cs / 100.0
    total_seconds += offset_seconds

    # è² ã®å€¤ã«ãªã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹
    if total_seconds < 0:
        total_seconds = 0

    # æ™‚åˆ»æ–‡å­—åˆ—ã«æˆ»ã™
    new_h = int(total_seconds // 3600)
    new_m = int((total_seconds % 3600) // 60)
    new_s = int(total_seconds % 60)
    new_cs = int((total_seconds % 1) * 100)

    return f"{new_h}:{new_m:02d}:{new_s:02d}.{new_cs:02d}"


def crop_video(input_path: str, output_path: str, crop_top: float, crop_bottom: float,
               crop_left: float, crop_right: float) -> bool:
    """
    å‹•ç”»ã‚’ã‚¯ãƒ­ãƒƒãƒ—ã™ã‚‹

    Args:
        input_path: å…¥åŠ›å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        output_path: å‡ºåŠ›å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        crop_top: ä¸Šéƒ¨ã‚¯ãƒ­ãƒƒãƒ—ç‡ï¼ˆ0-100ï¼‰
        crop_bottom: ä¸‹éƒ¨ã‚¯ãƒ­ãƒƒãƒ—ç‡ï¼ˆ0-100ï¼‰
        crop_left: å·¦å´ã‚¯ãƒ­ãƒƒãƒ—ç‡ï¼ˆ0-100ï¼‰
        crop_right: å³å´ã‚¯ãƒ­ãƒƒãƒ—ç‡ï¼ˆ0-100ï¼‰

    Returns:
        æˆåŠŸã—ãŸå ´åˆTrue
    """
    # ã‚¯ãƒ­ãƒƒãƒ—è¨­å®šãŒã™ã¹ã¦0ã®å ´åˆã¯ã‚³ãƒ”ãƒ¼ã®ã¿
    if crop_top == 0 and crop_bottom == 0 and crop_left == 0 and crop_right == 0:
        import shutil
        shutil.copy2(input_path, output_path)
        return True

    try:
        # å‹•ç”»ã®è§£åƒåº¦ã‚’å–å¾—
        cmd_probe = [
            'ffprobe',
            '-v', 'error',
            '-select_streams', 'v:0',
            '-show_entries', 'stream=width,height',
            '-of', 'csv=p=0',
            input_path
        ]
        result = subprocess.run(cmd_probe, capture_output=True, text=True, check=True)
        width, height = map(int, result.stdout.strip().split(','))

        # æŒ‡å®šã®ã‚¯ãƒ­ãƒƒãƒ—ç‡ã§æš«å®šã‚µã‚¤ã‚ºã‚’ç®—å‡º
        crop_w = int(width * (1 - (crop_left + crop_right) / 100))
        crop_h = int(height * (1 - (crop_top + crop_bottom) / 100))
        crop_x = int(width * crop_left / 100)
        crop_y = int(height * crop_top / 100)

        # é«˜ã•ã‚’åŸºæº–ã«16:9ã¸åˆã‚ã›ã‚‹ï¼ˆä½™ç™½ãªã—ï¼‰ã€‚æ¨ªã§èª¿æ•´ã—ãã‚Œãªã„å ´åˆã®ã¿é«˜ã•ã‚’ã•ã‚‰ã«å‰Šã‚‹
        target_aspect = 16 / 9
        desired_w_from_h = int(crop_h * target_aspect)

        if desired_w_from_h <= crop_w and desired_w_from_h > 0:
            # å¹…ãŒååˆ†ã‚ã‚‹ã®ã§å·¦å³ã‚’å‰Šã£ã¦16:9ã«
            reduce_w = crop_w - desired_w_from_h
            crop_x += reduce_w // 2
            crop_w = desired_w_from_h
        else:
            # å¹…ãŒè¶³ã‚Šãªã„å ´åˆã®ã¿é«˜ã•å´ã‚’å‰Šã£ã¦åˆã‚ã›ã‚‹
            desired_h_from_w = int(crop_w / target_aspect)
            reduce_h = crop_h - desired_h_from_w
            crop_y += reduce_h // 2
            crop_h = desired_h_from_w

        # FFmpegã§ã‚¯ãƒ­ãƒƒãƒ—
        cmd = [
            'ffmpeg', '-y',
            '-i', input_path,
            '-vf', f'crop={crop_w}:{crop_h}:{crop_x}:{crop_y}',
            '-c:v', 'libvpx-vp9',
            '-crf', str(DEFAULT_CROP_CRF),
            '-b:v', str(DEFAULT_CROP_BITRATE),
            '-c:a', 'copy',
            output_path
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0:
            print(f"FFmpeg crop error: {result.stderr}")
            return False

        return True
    except subprocess.CalledProcessError as e:
        print(f"FFmpeg error cropping video: {e.stderr}")
        return False
    except FileNotFoundError:
        print(f"Error: Input file not found: {input_path}")
        return False
    except Exception as e:
        print(f"Unexpected error cropping video: {e}")
        return False


def apply_crop_or_copy(raw_video_path: str, cropped_path: str, config: Any) -> Optional[str]:
    """
    ã‚¯ãƒ­ãƒƒãƒ—è¨­å®šã«å¿œã˜ã¦ã‚¯ãƒ­ãƒƒãƒ—ã‚’é©ç”¨ã—ã€å‡ºåŠ›ãƒ‘ã‚¹ã‚’è¿”ã™ï¼ˆã‚¯ãƒ­ãƒƒãƒ—ãªã—ãªã‚‰ã‚³ãƒ”ãƒ¼ï¼‰
    """
    has_crop = (config.crop_top_percent != 0 or config.crop_bottom_percent != 0 or
                config.crop_left_percent != 0 or config.crop_right_percent != 0)
    try:
        if has_crop:
            print(f"\n[Crop] Applying crop settings...")
            print(f"  Top: {config.crop_top_percent}%, Bottom: {config.crop_bottom_percent}%")
            print(f"  Left: {config.crop_left_percent}%, Right: {config.crop_right_percent}%")
            success = crop_video(
                raw_video_path,
                cropped_path,
                config.crop_top_percent,
                config.crop_bottom_percent,
                config.crop_left_percent,
                config.crop_right_percent
            )
            if not success:
                print("âœ— Failed to crop video")
                return None
        else:
            import shutil
            shutil.copy2(raw_video_path, cropped_path)
        return cropped_path
    except Exception as e:
        print(f"âœ— Error in cropping: {e}")
        return None


def process_single_clip(config: Any, clip_index: int) -> tuple:
    """
    å˜ä¸€ã®ã‚¯ãƒªãƒƒãƒ—ã‚’å‡¦ç†ã™ã‚‹ï¼ˆchained configç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼‰

    Args:
        config: ClipConfig ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        clip_index: ã‚¯ãƒªãƒƒãƒ—ç•ªå·ï¼ˆ0å§‹ã¾ã‚Šï¼‰

    Returns:
        tuple: (video_path, subs_path, chat_overlay_path)
    """
    suffix = "" if clip_index == 0 else f"_{clip_index}"

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å®šç¾©
    clip_video_path = os.path.join(config.temp_dir, f"clip{suffix}.webm")
    clip_video_raw_path = os.path.join(config.temp_dir, f"clip{suffix}_raw.webm")
    subs_clip_path = os.path.join(config.temp_dir, f"subs_clip{suffix}.srt")
    chat_full_path = os.path.join(config.temp_dir, f"chat_full{suffix}.json")
    chat_clip_path = os.path.join(config.temp_dir, f"chat_clip{suffix}.json")
    chat_overlay_path = os.path.join(config.temp_dir, f"chat_overlay{suffix}.ass")

    print(f"\n{'='*60}")
    print(f"Processing Clip {clip_index + 1}")
    print(f"{'='*60}")

    # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æ±ºå®š
    if config.auto_download:
        print(f"\n[Clip {clip_index + 1}] Downloading and clipping video from YouTube...")
        try:
            success = download_and_clip_video(
                config.video_url,
                config.start_time,
                config.end_time,
                clip_video_raw_path,
                download_full=False
            )
            if not success:
                print(f"âœ— Failed to download and clip video for clip {clip_index + 1}")
                return None, None, None
            raw_video_path = clip_video_raw_path
        except Exception as e:
            print(f"âœ— Error downloading clip {clip_index + 1}: {e}")
            return None, None, None
    else:
        print(f"\n[Clip {clip_index + 1}] Using existing video file")
        if not config.webm_path:
            print("âœ— WEBM_PATH is required when AUTO_DOWNLOAD=false")
            return None, None, None
        raw_video_path = config.webm_path

    # ã‚¯ãƒ­ãƒƒãƒ—å‡¦ç†ã‚’é©ç”¨
    has_crop = (config.crop_top_percent != 0 or config.crop_bottom_percent != 0 or
                config.crop_left_percent != 0 or config.crop_right_percent != 0)

    if has_crop:
        print(f"\n[Clip {clip_index + 1}] Applying crop settings...")
        print(f"  Top: {config.crop_top_percent}%, Bottom: {config.crop_bottom_percent}%")
        print(f"  Left: {config.crop_left_percent}%, Right: {config.crop_right_percent}%")
        cropped = apply_crop_or_copy(raw_video_path, clip_video_path, config)
        if not cropped:
            print(f"âœ— Failed to crop video for clip {clip_index + 1}")
            return None, None, None
        video_source_path = cropped
        print(f"âœ“ Video cropped successfully")
    else:
        # ã‚¯ãƒ­ãƒƒãƒ—ä¸è¦ã®å ´åˆã¯ã‚³ãƒ”ãƒ¼
        shutil.copy2(raw_video_path, clip_video_path)
        video_source_path = clip_video_path

    # ã‚¹ãƒ†ãƒƒãƒ—1: Whisperå­—å¹•ç”Ÿæˆ
    print(f"\n[Clip {clip_index + 1}] Generating subtitles with Whisper...")
    try:
        success = generate_subtitles_with_whisper(
            video_source_path,
            subs_clip_path,
            model_size="large",
            language="ja"
        )
        if not success:
            print("  Note: Failed to generate subtitles")
    except Exception as e:
        print(f"âœ— Error in subtitle generation: {e}")

    # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒãƒ£ãƒƒãƒˆå–å¾—
    print(f"\n[Clip {clip_index + 1}] Fetching live chat from YouTube...")
    try:
        success = fetch_chat(config.video_url, chat_full_path)
        if not success:
            print("  Note: Chat replay not available")
            chat_full_path = None
    except Exception as e:
        print(f"âœ— Error fetching chat: {e}")
        chat_full_path = None

    # ã‚¹ãƒ†ãƒƒãƒ—3: ãƒãƒ£ãƒƒãƒˆæŠ½å‡º
    if chat_full_path and os.path.exists(chat_full_path):
        print(f"\n[Clip {clip_index + 1}] Extracting chat messages for clip...")
        try:
            count = load_and_extract_chat(
                chat_full_path,
                chat_clip_path,
                config.start_time,
                config.end_time,
                delay_seconds=config.chat_delay_seconds,
                dedup_window_seconds=config.chat_dedup_window_seconds,
                dedup_by_author=config.chat_dedup_by_author
            )
            if count == 0:
                chat_clip_path = None
        except Exception as e:
            print(f"âœ— Error extracting chat: {e}")
            chat_clip_path = None
    else:
        print(f"\n[Clip {clip_index + 1}] Skipped chat extraction (no chat available)")
        chat_clip_path = None

    # ã‚¹ãƒ†ãƒƒãƒ—4: ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”Ÿæˆ
    if chat_clip_path and os.path.exists(chat_clip_path):
        print(f"\n[Clip {clip_index + 1}] Generating chat overlay (ASS)...")
        try:
            overlay_config = OverlayConfig()
            count = generate_overlay_from_file(
                chat_clip_path,
                chat_overlay_path,
                overlay_config
            )
            if count == 0:
                chat_overlay_path = None
        except Exception as e:
            print(f"âœ— Error generating overlay: {e}")
            chat_overlay_path = None
    else:
        print(f"\n[Clip {clip_index + 1}] Skipped overlay generation (no chat available)")
        chat_overlay_path = None

    return video_source_path, subs_clip_path, chat_overlay_path


def run_prepare_pipeline(config_path: str) -> bool:
    """
    ç´ ææº–å‚™ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆå­—å¹•ç”Ÿæˆã¾ã§ã€å‹•ç”»åˆæˆã¯è¡Œã‚ãªã„ï¼‰
    NEXT_CONFIGãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€é€£é–çš„ã«è¤‡æ•°ã®ã‚¯ãƒªãƒƒãƒ—ã‚’å‡¦ç†ã™ã‚‹

    Args:
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        æˆåŠŸã—ãŸã‹ã©ã†ã‹
    """
    print("=" * 60)
    print("KIRINUKI Processor - Prepare Materials")
    print("=" * 60)

    # ã‚¹ãƒ†ãƒƒãƒ—0: è¨­å®šèª­ã¿è¾¼ã¿ï¼ˆé€£é–ãƒã‚§ãƒƒã‚¯ï¼‰
    print("\n[Step 0] Loading configuration...")
    configs = []
    current_config_path = config_path
    visited_configs = set()

    # é€£é–è¨­å®šã‚’ã™ã¹ã¦èª­ã¿è¾¼ã‚€
    while current_config_path:
        # å¾ªç’°å‚ç…§ãƒã‚§ãƒƒã‚¯
        if current_config_path in visited_configs:
            print(f"âœ— Error: Circular reference detected in config chain: {current_config_path}")
            return False
        visited_configs.add(current_config_path)

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        try:
            config = load_config_from_file(current_config_path)
            configs.append(config)
            print(f"âœ“ Configuration loaded: {current_config_path}")
            print(f"  Video URL: {config.video_url}")
            print(f"  Start time: {config.start_time}")
            print(f"  End time: {config.end_time or 'Not specified'}")

            # æ¬¡ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
            if config.next_config:
                print(f"  â†’ Next config: {config.next_config}")
                current_config_path = config.next_config
            else:
                current_config_path = None
        except Exception as e:
            print(f"âœ— Failed to load configuration {current_config_path}: {e}")
            return False

    print(f"\nâœ“ Total clips to process: {len(configs)}")

    # å‡ºåŠ›ãƒ»ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆï¼ˆæœ€åˆã®configã®è¨­å®šã‚’ä½¿ç”¨ï¼‰
    base_config = configs[0]
    os.makedirs(base_config.output_dir, exist_ok=True)
    os.makedirs(base_config.temp_dir, exist_ok=True)

    # å„ã‚¯ãƒªãƒƒãƒ—ã‚’å‡¦ç†
    all_clips = []
    for i, config in enumerate(configs):
        result = process_single_clip(config, i)
        if result[0] is None:
            print(f"âœ— Failed to process clip {i + 1}")
            return False
        all_clips.append(result)

    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print("âœ“ Preparation completed successfully!")
    print(f"\nProcessed {len(all_clips)} clip(s):")
    for i, (video_path, subs_path, chat_path) in enumerate(all_clips):
        suffix = "" if i == 0 else f"_{i}"
        print(f"\nClip {i + 1}:")
        print(f"  Video: clip{suffix}.webm")
        if os.path.exists(subs_path):
            print(f"  Subtitles: subs_clip{suffix}.srt")
        if chat_path and os.path.exists(chat_path):
            print(f"  Chat overlay: chat_overlay{suffix}.ass")

    print("\nğŸ“ Next steps:")
    if len(all_clips) > 1:
        print(f"  1. Edit subtitles if needed (subs_clip.srt, subs_clip_1.srt, ...)")
        print(f"  2. Run: python main.py compose {config_path}")
        print(f"     â†’ This will concatenate all {len(all_clips)} clips into one video")
    else:
        print(f"  1. Edit subtitles: {os.path.join(base_config.temp_dir, 'subs_clip.srt')}")
        print(f"  2. Run: python main.py compose {config_path}")
    print("=" * 60)

    return True


def run_resub_pipeline(config_path: str) -> bool:
    """
    å­—å¹•å†ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

    æ—¢ã«prepareãŒå®Œäº†ã—ã¦ã„ã‚‹çŠ¶æ…‹ã§ã€Whisperå­—å¹•ã ã‘ã‚’å†ç”Ÿæˆã™ã‚‹ãŸã‚ã®ç°¡æ˜“ã‚³ãƒãƒ³ãƒ‰ã€‚
    å­—å¹•ãŒé£›ã‚“ã§ã„ã‚‹å ´åˆã‚„ã€åˆ¥ã®Whisperãƒ¢ãƒ‡ãƒ«ã§è©¦ã—ãŸã„å ´åˆã«ä¾¿åˆ©ã€‚

    å®Ÿè¡Œå†…å®¹ï¼š
    - Step 1: Whisperå­—å¹•ç”Ÿæˆï¼ˆsubs_clip.srtç”Ÿæˆï¼‰

    Args:
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        bool: æˆåŠŸã—ãŸå ´åˆTrue
    """
    print("=" * 60)
    print("KIRINUKI PROCESSOR - RESUB PIPELINE")
    print("=" * 60)
    print("\nThis will regenerate subtitles with Whisper")
    print("Make sure you have already run 'prepare' command.\n")

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    config = load_config_from_file(config_path)

    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèª
    if not os.path.exists(config.temp_dir):
        print(f"âœ— Error: temp directory not found: {config.temp_dir}")
        print("  Please run 'prepare' command first.")
        return False

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å®šç¾©
    clip_video_path = os.path.join(config.temp_dir, "clip.webm")
    subs_clip_path = os.path.join(config.temp_dir, "subs_clip.srt")

    # clip.webmã®å­˜åœ¨ç¢ºèª
    if not os.path.exists(clip_video_path):
        print(f"âœ— Error: clip.webm not found: {clip_video_path}")
        print("  Please run 'prepare' command first.")
        return False

    # ã‚¹ãƒ†ãƒƒãƒ—1: Whisperå­—å¹•ç”Ÿæˆ
    print("\n[Step 1] Generating subtitles with Whisper...")
    try:
        success = generate_subtitles_with_whisper(
            clip_video_path,
            subs_clip_path,
            model_size="large",
            language="ja"
        )
        if not success:
            print("  âœ— Failed to generate subtitles")
            return False
    except Exception as e:
        print(f"âœ— Error in Step 1: {e}")
        return False

    print("\n" + "=" * 60)
    print("RESUB PIPELINE COMPLETED!")
    print("=" * 60)
    print("\nNext steps:")
    print(f"  1. Check subtitles: {subs_clip_path}")
    print(f"  2. Run: python main.py compose {config_path}")
    print()

    return True


def run_rechat_pipeline(config_path: str) -> bool:
    """
    ãƒãƒ£ãƒƒãƒˆå†ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

    æ—¢ã«prepareãŒå®Œäº†ã—ã¦ã„ã‚‹çŠ¶æ…‹ã§ã€config.txtã®CHAT_DELAY_SECONDSã‚’å¤‰æ›´ã—ãŸå¾Œã«
    ãƒãƒ£ãƒƒãƒˆã ã‘ã‚’å†ç”Ÿæˆã™ã‚‹ãŸã‚ã®ç°¡æ˜“ã‚³ãƒãƒ³ãƒ‰ã€‚

    å®Ÿè¡Œå†…å®¹ï¼š
    - Step 3: ãƒãƒ£ãƒƒãƒˆæŠ½å‡ºï¼ˆchat_clip.jsonç”Ÿæˆï¼‰
    - Step 4: ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”Ÿæˆï¼ˆchat_overlay.assç”Ÿæˆï¼‰

    Args:
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        bool: æˆåŠŸã—ãŸå ´åˆTrue
    """
    print("=" * 60)
    print("KIRINUKI PROCESSOR - RECHAT PIPELINE")
    print("=" * 60)
    print("\nThis will regenerate chat overlay with new CHAT_DELAY_SECONDS setting")
    print("Make sure you have already run 'prepare' command.\n")

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    config = load_config_from_file(config_path)

    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèª
    if not os.path.exists(config.temp_dir):
        print(f"âœ— Error: temp directory not found: {config.temp_dir}")
        print("  Please run 'prepare' command first.")
        return False

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å®šç¾©
    chat_full_path = os.path.join(config.temp_dir, "chat_full.json")
    chat_clip_path = os.path.join(config.temp_dir, "chat_clip.json")
    chat_overlay_path = os.path.join(config.temp_dir, "chat_overlay.ass")

    # chat_full.jsonã®å­˜åœ¨ç¢ºèª
    if not os.path.exists(chat_full_path):
        print(f"âœ— Error: chat_full.json not found: {chat_full_path}")
        print("  Please run 'prepare' command first, or this video has no live chat.")
        return False

    # ã‚¹ãƒ†ãƒƒãƒ—3: ãƒãƒ£ãƒƒãƒˆæŠ½å‡º
    print("\n[Step 3] Extracting chat messages for clip...")
    print(f"  Chat delay: {config.chat_delay_seconds}s")
    try:
        count = load_and_extract_chat(
            chat_full_path,
            chat_clip_path,
            config.start_time,
            config.end_time,
            delay_seconds=config.chat_delay_seconds,
            dedup_window_seconds=config.chat_dedup_window_seconds,
            dedup_by_author=config.chat_dedup_by_author
        )
        if count == 0:
            print("  Warning: No chat messages in the specified time range")
            chat_clip_path = None
    except Exception as e:
        print(f"âœ— Error in Step 3: {e}")
        return False

    # ã‚¹ãƒ†ãƒƒãƒ—4: ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”Ÿæˆ
    if chat_clip_path:
        print("\n[Step 4] Generating chat overlay...")
        try:
            overlay_config = OverlayConfig()
            count = generate_overlay_from_file(
                chat_clip_path,
                chat_overlay_path,
                overlay_config
            )
            if count == 0:
                print("  Warning: No chat messages were added to overlay")
        except Exception as e:
            print(f"âœ— Error in Step 4: {e}")
            return False
    else:
        print("\n[Step 4] Skipped (no chat messages)")

    print("\n" + "=" * 60)
    print("RECHAT PIPELINE COMPLETED!")
    print("=" * 60)
    print("\nNext step:")
    print(f"  python main.py compose {config_path}")
    print()

    return True


def run_clear_pipeline(config_path: str, keep_videos: bool = False) -> bool:
    """
    ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

    æ¬¡ã®å‹•ç”»ä½œæˆã®ãŸã‚ã«ä¸è¦ãªä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã™ã€‚
    å‰Šé™¤å¯¾è±¡ï¼š
    - å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ*.srt, *.assï¼‰
    - ãƒãƒ£ãƒƒãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ*.jsonï¼‰
    - ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆchat_overlay*.assï¼‰
    - ã‚¿ã‚¤ãƒˆãƒ«ãƒãƒ¼ï¼ˆtitle_bar.assï¼‰
    - é€£çµãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆconcatenated.webm, *_merged.*)
    - å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ--keep-videosã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ä¿æŒå¯èƒ½ï¼‰

    ä¿æŒã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ï¼š
    - data/output/final.mp4
    - data/output/description.txt

    Args:
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        keep_videos: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆclip*.webmï¼‰ã‚’ä¿æŒã™ã‚‹ã‹

    Returns:
        bool: æˆåŠŸã—ãŸå ´åˆTrue
    """
    print("=" * 60)
    print("KIRINUKI PROCESSOR - CLEAR TEMP FILES")
    print("=" * 60)
    print(f"\nThis will delete temporary files from {config_path}")
    if keep_videos:
        print("  Videos (clip*.webm) will be kept")
    else:
        print("  All temporary files including videos will be deleted")
    print()

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    config = load_config_from_file(config_path)

    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
    if not os.path.exists(config.temp_dir):
        print(f"âœ“ Temp directory does not exist: {config.temp_dir}")
        print("  Nothing to clear")
        return True

    # å‰Šé™¤å¯¾è±¡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
    patterns_to_delete = [
        "subs_clip*.srt",
        "subs_clip*.ass",
        "chat_full*.json",
        "chat_clip*.json",
        "chat_overlay*.ass",
        "title_bar.ass",
        "concatenated.webm",
        "*_merged.*",
    ]

    if not keep_videos:
        patterns_to_delete.extend([
            "clip*.webm",
            "clip*_raw.webm",
        ])

    deleted_count = 0

    for pattern in patterns_to_delete:
        full_pattern = os.path.join(config.temp_dir, pattern)
        matched_files = glob.glob(full_pattern)
        for file_path in matched_files:
            try:
                os.remove(file_path)
                print(f"âœ“ Deleted: {os.path.basename(file_path)}")
                deleted_count += 1
            except Exception as e:
                print(f"âœ— Failed to delete {os.path.basename(file_path)}: {e}")

    print("\n" + "=" * 60)
    print("CLEAR COMPLETED!")
    print("=" * 60)
    print(f"\nDeleted {deleted_count} file(s)")

    if keep_videos:
        print("\nNote: Video files (clip*.webm) were kept")
        print("  Use 'python main.py clear config.txt' to delete them")

    print()
    return True


def run_output_pipeline(config_path: str) -> bool:
    """
    å‡ºåŠ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆå®Œæˆå‹•ç”»ã¨è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¿ã‚¤ãƒˆãƒ«åã®ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ï¼‰

    å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«åã§ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã€ä»¥ä¸‹ã‚’ã‚³ãƒ”ãƒ¼ï¼š
    - final.mp4 â†’ {TITLE}/final.mp4
    - description.txt â†’ {TITLE}/description.txt
    - config.txt â†’ {TITLE}/config.txt

    Args:
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        bool: æˆåŠŸã—ãŸå ´åˆTrue
    """
    print("=" * 60)
    print("KIRINUKI PROCESSOR - OUTPUT PIPELINE")
    print("=" * 60)
    print("\nThis will copy final.mp4, description.txt, and config to a titled folder\n")

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    config = load_config_from_file(config_path)

    # ã‚¿ã‚¤ãƒˆãƒ«ãƒã‚§ãƒƒã‚¯
    if not config.title:
        print("âœ— Error: TITLE is not set in config.txt")
        print("  Please set TITLE parameter in your config file.")
        return False

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å®šç¾©
    final_mp4_path = os.path.join(config.output_dir, "final.mp4")
    description_path = os.path.join(config.output_dir, "description.txt")

    # final.mp4ã®å­˜åœ¨ç¢ºèª
    if not os.path.exists(final_mp4_path):
        print(f"âœ— Error: final.mp4 not found: {final_mp4_path}")
        print("  Please run 'compose' command first.")
        return False

    # ã‚¿ã‚¤ãƒˆãƒ«åã‹ã‚‰ãƒ•ã‚©ãƒ«ãƒ€åã‚’ä½œæˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã§ä½¿ãˆãªã„æ–‡å­—ã‚’ç½®æ›ï¼‰
    import re
    safe_title = re.sub(r'[<>:"/\\|?*]', '_', config.title)
    output_folder = os.path.join(config.output_dir, safe_title)

    # ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
    os.makedirs(output_folder, exist_ok=True)
    print(f"âœ“ Created output folder: {output_folder}")

    # 1. final.mp4ã‚’ã‚³ãƒ”ãƒ¼
    dest_mp4 = os.path.join(output_folder, "final.mp4")
    shutil.copy2(final_mp4_path, dest_mp4)
    print(f"âœ“ Copied: final.mp4")

    # 2. description.txtã‚’ã‚³ãƒ”ãƒ¼ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
    if os.path.exists(description_path):
        dest_description = os.path.join(output_folder, "description.txt")
        shutil.copy2(description_path, dest_description)
        print(f"âœ“ Copied: description.txt")

    # 3. config.txtã‚’ã‚³ãƒ”ãƒ¼
    dest_config = os.path.join(output_folder, "config.txt")
    shutil.copy2(config_path, dest_config)
    print(f"âœ“ Copied: config.txt")

    print("\n" + "=" * 60)
    print("OUTPUT PIPELINE COMPLETED!")
    print("=" * 60)
    print(f"\nOutput folder: {output_folder}")
    print("Files saved:")
    print(f"  - final.mp4")
    print(f"  - config.txt")
    if os.path.exists(description_path):
        print(f"  - description.txt")
    print()

    return True


def run_compose_pipeline(config_path: str) -> bool:
    """
    å‹•ç”»åˆæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆæ—¢å­˜ã®ç´ æã‚’ä½¿ã£ã¦å‹•ç”»ã‚’åˆæˆï¼‰
    NEXT_CONFIGãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€è¤‡æ•°ã®ã‚¯ãƒªãƒƒãƒ—ã‚’é€£çµã™ã‚‹

    Args:
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        æˆåŠŸã—ãŸã‹ã©ã†ã‹
    """
    print("=" * 60)
    print("KIRINUKI Processor - Compose Video")
    print("=" * 60)

    # è¨­å®šèª­ã¿è¾¼ã¿ï¼ˆé€£é–ãƒã‚§ãƒƒã‚¯ï¼‰
    print("\n[Loading configuration...]")
    configs = []
    current_config_path = config_path
    visited_configs = set()

    while current_config_path:
        if current_config_path in visited_configs:
            print(f"âœ— Error: Circular reference detected")
            return False
        visited_configs.add(current_config_path)

        try:
            config = load_config_from_file(current_config_path)
            configs.append(config)
            current_config_path = config.next_config
        except Exception as e:
            print(f"âœ— Failed to load configuration: {e}")
            return False

    base_config = configs[0]
    print(f"âœ“ Loaded {len(configs)} config(s)")

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
    clip_count = len(configs)
    video_paths = []
    subs_paths_srt = []
    subs_paths_ass = []
    chat_overlay_paths = []

    print(f"\nChecking files for {clip_count} clip(s)...")
    for i in range(clip_count):
        suffix = "" if i == 0 else f"_{i}"

        # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«
        clip_video_path = os.path.join(base_config.temp_dir, f"clip{suffix}.webm")
        if not os.path.exists(clip_video_path):
            print(f"âœ— Video file not found: {clip_video_path}")
            print("  Please run 'python main.py prepare' first")
            return False
        video_paths.append(clip_video_path)

        # å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆSRTï¼‰
        subs_srt = os.path.join(base_config.temp_dir, f"subs_clip{suffix}.srt")
        if os.path.exists(subs_srt):
            subs_paths_srt.append(subs_srt)
        else:
            subs_paths_srt.append(None)

        # å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆASSï¼‰
        subs_ass = os.path.join(base_config.temp_dir, f"subs_clip{suffix}.ass")
        subs_paths_ass.append(subs_ass)

        # ãƒãƒ£ãƒƒãƒˆã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
        chat_overlay = os.path.join(base_config.temp_dir, f"chat_overlay{suffix}.ass")
        if os.path.exists(chat_overlay):
            chat_overlay_paths.append(chat_overlay)
        else:
            chat_overlay_paths.append(None)

    # è¤‡æ•°ã‚¯ãƒªãƒƒãƒ—ã®å ´åˆã¯é€£çµå‡¦ç†
    final_output_path = os.path.join(base_config.output_dir, "final.mp4")

    if clip_count > 1:
        print(f"\n[Concatenating {clip_count} clips...]")

        # å‹•ç”»ã‚’é€£çµ
        concatenated_video_path = os.path.join(base_config.temp_dir, "concatenated.webm")
        print("  Concatenating videos...")
        success = concatenate_videos(video_paths, concatenated_video_path)
        if not success:
            print("âœ— Failed to concatenate videos")
            return False
        video_source_path = concatenated_video_path

        # å­—å¹•ã‚’ãƒãƒ¼ã‚¸ï¼ˆSRTï¼‰
        merged_subs_srt = os.path.join(base_config.temp_dir, "subs_clip_merged.srt")
        valid_subs_srt = [s for s in subs_paths_srt if s and os.path.exists(s)]
        if valid_subs_srt:
            print("  Merging subtitles...")
            success = merge_subtitle_files(valid_subs_srt, merged_subs_srt)
            if success:
                subs_clip_path_srt = merged_subs_srt
            else:
                subs_clip_path_srt = None
        else:
            subs_clip_path_srt = None

        # ãƒãƒ£ãƒƒãƒˆã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’ãƒãƒ¼ã‚¸ï¼ˆASSï¼‰
        merged_chat_overlay = os.path.join(base_config.temp_dir, "chat_overlay_merged.ass")
        valid_chat_overlays = [c for c in chat_overlay_paths if c and os.path.exists(c)]
        if valid_chat_overlays:
            print("  Merging chat overlays...")
            success = merge_ass_overlays(valid_chat_overlays, merged_chat_overlay, video_paths)
            if success:
                chat_overlay_path = merged_chat_overlay
            else:
                chat_overlay_path = None
        else:
            chat_overlay_path = None

        print("âœ“ Concatenation completed")
    else:
        # å˜ä¸€ã‚¯ãƒªãƒƒãƒ—ã®å ´åˆï¼ˆå¾“æ¥ã®å‡¦ç†ï¼‰
        video_source_path = video_paths[0]
        subs_clip_path_srt = subs_paths_srt[0]
        chat_overlay_path = chat_overlay_paths[0]

    print(f"\nUsing files:")
    print(f"  Video: {video_source_path}")

    # å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ï¼ˆSRTâ†’ASSå¤‰æ›ï¼‰
    subs_clip_path_ass = None
    subtitle_path = None

    if subs_clip_path_srt and os.path.exists(subs_clip_path_srt):
        # ãƒãƒ¼ã‚¸ã•ã‚ŒãŸå­—å¹• or å˜ä¸€å­—å¹•ã®ASSå¤‰æ›
        if clip_count > 1:
            subs_clip_path_ass = os.path.join(base_config.temp_dir, "subs_clip_merged.ass")
        else:
            subs_clip_path_ass = os.path.join(base_config.temp_dir, "subs_clip.ass")

        try:
            bold_variant = subs_clip_path_ass.replace(".ass", "_bold.ass")
            needs_regen = (
                not os.path.exists(subs_clip_path_ass)
                or (base_config.subtitle_style == "bold" and not os.path.exists(bold_variant))
                or os.path.getmtime(subs_clip_path_ass) < os.path.getmtime(subs_clip_path_srt)
                or (os.path.exists(bold_variant) and os.path.getmtime(bold_variant) < os.path.getmtime(subs_clip_path_srt))
            )
            if needs_regen:
                print("  Updating styled subtitles from edited SRT...")
                convert_srt_to_ass(subs_clip_path_srt, subs_clip_path_ass)
        except Exception as e:
            print(f"  Warning: Failed to regenerate ASS from SRT: {e}")

    if subs_clip_path_ass and os.path.exists(subs_clip_path_ass):
        subtitle_candidate = subs_clip_path_ass
        if base_config.subtitle_style == "bold":
            bold_path = subs_clip_path_ass.replace(".ass", "_bold.ass")
            if os.path.exists(bold_path):
                subtitle_candidate = bold_path
        subtitle_path = subtitle_candidate
        print(f"  Subtitles: {subtitle_path} (styled)")
    elif subs_clip_path_srt and os.path.exists(subs_clip_path_srt):
        subtitle_path = subs_clip_path_srt
        print(f"  Subtitles: {subs_clip_path_srt}")
    else:
        print("  Subtitles: (none)")

    overlay_path = None
    if chat_overlay_path and os.path.exists(chat_overlay_path):
        overlay_path = chat_overlay_path
        print(f"  Chat overlay: {chat_overlay_path}")
    else:
        print(f"  Chat overlay: (none)")

    # ã‚¿ã‚¤ãƒˆãƒ«ãƒãƒ¼ç”Ÿæˆï¼ˆTITLEãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
    title_bar_path = os.path.join(base_config.temp_dir, "title_bar.ass")
    title_overlay_path = None
    if base_config.title:
        print(f"\n[Generating title bar...]")
        try:
            success = generate_title_bar(
                base_config.title,
                title_bar_path,
                video_width=1920,
                video_height=1080,
                slide_duration=1.2,
                display_duration=None  # å‹•ç”»çµ‚äº†ã¾ã§è¡¨ç¤º
            )
            if success:
                title_overlay_path = title_bar_path
                print(f"  Title bar: {title_bar_path}")
        except Exception as e:
            print(f"âœ— Error generating title bar: {e}")

    # ãƒ­ã‚´ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆå›ºå®šï¼‰
    logo_path = "data/input/ã²ã‚ã‚†ãè¦–ç‚¹ã€åˆ‡ã‚ŠæŠœãã€‘.png"
    if not os.path.exists(logo_path):
        logo_path = None
        print(f"  Logo file not found: {logo_path}")

    # ã‚¹ãƒ†ãƒƒãƒ—5: å‹•ç”»åˆæˆ
    print("\n[Step 5] Composing final video...")
    try:
        # ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’çµåˆï¼ˆchat + titleï¼‰
        overlays = []
        if overlay_path:
            overlays.append(overlay_path)
        if title_overlay_path:
            overlays.append(title_overlay_path)

        # ã™ã¹ã¦ã®ã‚¯ãƒªãƒƒãƒ—ãŒæ—¢ã«Step0ã§ã‚¯ãƒ­ãƒƒãƒ—æ¸ˆã¿ã®ãŸã‚ã€composeæ™‚ã¯å†ã‚¯ãƒ­ãƒƒãƒ—ã—ãªã„
        crop_top = crop_bottom = crop_left = crop_right = 0.0

        success = compose_video(
            video_source_path,
            final_output_path,
            subtitle_path=subtitle_path,
            overlay_path=overlay_path,
            title_overlay_path=title_overlay_path,
            logo_path=logo_path,
            crop_top_percent=crop_top,
            crop_bottom_percent=crop_bottom,
            crop_left_percent=crop_left,
            crop_right_percent=crop_right
        )
        if not success:
            print("âœ— Failed to compose video")
            return False
    except Exception as e:
        print(f"âœ— Error in Step 5: {e}")
        return False

    # ã‚¹ãƒ†ãƒƒãƒ—6: YouTubeèª¬æ˜æ¬„ç”Ÿæˆï¼ˆå­—å¹•ãŒå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
    description_output_path = os.path.join(base_config.output_dir, "description.txt")
    if subs_clip_path_srt and os.path.exists(subs_clip_path_srt):
        print("\n[Step 6] Generating YouTube description...")
        try:
            success = generate_youtube_description(
                subs_clip_path_srt,
                description_output_path,
                prompt_template_path="data/input/setumei",
                video_url=base_config.video_url
            )
            if success:
                print(f"  Description: {description_output_path}")
        except Exception as e:
            print(f"  Note: Failed to generate description: {e}")
    else:
        print("\n[Step 6] Skipped (no subtitles available)")

    print("\n" + "=" * 60)
    print("âœ“ Composition completed successfully!")
    print(f"  Final output: {final_output_path}")
    if os.path.exists(description_output_path):
        print(f"  Description: {description_output_path}")
    print("=" * 60)

    return True


def run_full_pipeline(config_path: str, skip_steps: list = None) -> bool:
    """
    å…¨ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œã™ã‚‹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

    Args:
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        skip_steps: ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒªã‚¹ãƒˆï¼ˆä¾‹: [1, 3]ï¼‰

    Returns:
        æˆåŠŸã—ãŸã‹ã©ã†ã‹
    """
    if skip_steps is None:
        skip_steps = []

    print("=" * 60)
    print("KIRINUKI Processor - Full Pipeline")
    print("=" * 60)

    # ã‚¹ãƒ†ãƒƒãƒ—0: è¨­å®šèª­ã¿è¾¼ã¿
    print("\n[Step 0] Loading configuration...")
    try:
        config = load_config_from_file(config_path)
        print(f"âœ“ Configuration loaded")
        print(f"  Video URL: {config.video_url}")
        print(f"  Start time: {config.start_time}")
        print(f"  End time: {config.end_time or 'Not specified'}")
        print(f"  Auto download: {config.auto_download}")
        if config.webm_path:
            print(f"  WebM path: {config.webm_path}")
    except Exception as e:
        print(f"âœ— Failed to load configuration: {e}")
        return False

    # å‡ºåŠ›ãƒ»ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    os.makedirs(config.output_dir, exist_ok=True)
    os.makedirs(config.temp_dir, exist_ok=True)

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å®šç¾©
    clip_video_path = os.path.join(config.temp_dir, "clip.webm")
    clip_video_raw_path = os.path.join(config.temp_dir, "clip_raw.webm")
    subs_full_path = os.path.join(config.temp_dir, "subs_full.srt")
    subs_clip_path = os.path.join(config.temp_dir, "subs_clip.srt")
    chat_full_path = os.path.join(config.temp_dir, "chat_full.json")
    chat_clip_path = os.path.join(config.temp_dir, "chat_clip.json")
    chat_overlay_path = os.path.join(config.temp_dir, "chat_overlay.ass")
    final_output_path = os.path.join(config.output_dir, "final.mp4")

    # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æ±ºå®šï¼ˆrawâ†’cropâ†’clip.webm ã«çµ±ä¸€ï¼‰
    if config.auto_download:
        if 0 not in skip_steps:
            print("\n[Step 0] Downloading and clipping video from YouTube...")
            try:
                success = download_and_clip_video(
                    config.video_url,
                    config.start_time,
                    config.end_time,
                    clip_video_raw_path,
                    download_full=False
                )
                if not success:
                    print("âœ— Failed to download and clip video")
                    return False
            except Exception as e:
                print(f"âœ— Error in Step 0: {e}")
                return False
        else:
            print("\n[Step 0] Skipped download (assuming raw clip already exists)")
        raw_video_path = clip_video_raw_path
    else:
        print("\n[Step 0] Using existing video file")
        if not config.webm_path:
            print("âœ— WEBM_PATH is required when AUTO_DOWNLOAD=false")
            return False
        raw_video_path = config.webm_path

    # ã‚¯ãƒ­ãƒƒãƒ—é©ç”¨ï¼ˆskipã—ã¦ã„ã¦ã‚‚ã‚¯ãƒ­ãƒƒãƒ—ã¯è¡Œã†ï¼‰
    cropped = apply_crop_or_copy(raw_video_path, clip_video_path, config)
    if not cropped:
        return False
    video_source_path = cropped

    # ã‚¹ãƒ†ãƒƒãƒ—1: Whisperå­—å¹•ç”Ÿæˆ
    if 1 not in skip_steps:
        print("\n[Step 1] Generating subtitles with Whisper...")
        try:
            success = generate_subtitles_with_whisper(
                video_source_path,
                subs_clip_path,
                model_size="large",
                language="ja"
            )
            if not success:
                print("  Note: Failed to generate subtitles, will proceed without them")
                subs_clip_path = None
        except Exception as e:
            print(f"âœ— Error in Step 1: {e}")
            subs_clip_path = None
    else:
        print("\n[Step 1] Skipped")

    # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒãƒ£ãƒƒãƒˆå–å¾—
    if 2 not in skip_steps:
        print("\n[Step 2] Fetching live chat from YouTube...")
        try:
            success = fetch_chat(config.video_url, chat_full_path)
            if not success:
                print("  Note: Chat replay not available, will proceed without it")
                chat_full_path = None
        except Exception as e:
            print(f"âœ— Error in Step 2: {e}")
            chat_full_path = None
    else:
        print("\n[Step 2] Skipped")

    # ã‚¹ãƒ†ãƒƒãƒ—3: ãƒãƒ£ãƒƒãƒˆæŠ½å‡º
    if 3 not in skip_steps and chat_full_path and os.path.exists(chat_full_path):
        print("\n[Step 3] Extracting chat messages for clip...")
        try:
            count = load_and_extract_chat(
                chat_full_path,
                chat_clip_path,
                config.start_time,
                config.end_time,
                delay_seconds=config.chat_delay_seconds,
                dedup_window_seconds=config.chat_dedup_window_seconds,
                dedup_by_author=config.chat_dedup_by_author
            )
            if count == 0:
                chat_clip_path = None
        except Exception as e:
            print(f"âœ— Error in Step 3: {e}")
            chat_clip_path = None
    else:
        print("\n[Step 3] Skipped (no chat available)")
        chat_clip_path = None

    # ã‚¹ãƒ†ãƒƒãƒ—4: ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”Ÿæˆ
    if 4 not in skip_steps and chat_clip_path and os.path.exists(chat_clip_path):
        print("\n[Step 4] Generating chat overlay (ASS)...")
        try:
            overlay_config = OverlayConfig()
            count = generate_overlay_from_file(
                chat_clip_path,
                chat_overlay_path,
                overlay_config
            )
            if count == 0:
                chat_overlay_path = None
        except Exception as e:
            print(f"âœ— Error in Step 4: {e}")
            chat_overlay_path = None
    else:
        print("\n[Step 4] Skipped (no chat available)")
        chat_overlay_path = None

    subtitle_for_compose = None
    if subs_clip_path and os.path.exists(subs_clip_path):
        subs_clip_path_ass = subs_clip_path.replace(".srt", ".ass")
        try:
            needs_regen = (not os.path.exists(subs_clip_path_ass) or
                           os.path.getmtime(subs_clip_path_ass) < os.path.getmtime(subs_clip_path))
            if needs_regen:
                print("  Updating styled subtitles from edited SRT...")
                convert_srt_to_ass(subs_clip_path, subs_clip_path_ass)
        except Exception as e:
            print(f"  Warning: Failed to regenerate ASS from SRT: {e}")

        if os.path.exists(subs_clip_path_ass):
            subtitle_for_compose = subs_clip_path_ass
        else:
            subtitle_for_compose = subs_clip_path

    # ã‚¹ãƒ†ãƒƒãƒ—5: å‹•ç”»åˆæˆ
    if 5 not in skip_steps:
        print("\n[Step 5] Composing final video...")
        try:
            success = compose_video(
                video_source_path,
                final_output_path,
                subtitle_path=subtitle_for_compose,
                overlay_path=chat_overlay_path if chat_overlay_path and os.path.exists(chat_overlay_path) else None
            )
            if not success:
                print("âœ— Failed to compose video")
                return False
        except Exception as e:
            print(f"âœ— Error in Step 6: {e}")
            return False
    else:
        print("\n[Step 6] Skipped")

    print("\n" + "=" * 60)
    print("âœ“ Pipeline completed successfully!")
    print(f"  Final output: {final_output_path}")
    print("=" * 60)

    return True


def run_crop_step(config_path: str) -> bool:
    """
    Step0.5: æ—¢å­˜ã®clip_raw.webmã«ã‚¯ãƒ­ãƒƒãƒ—ã‚’é©ç”¨ã—ã¦clip.webmã‚’ç”Ÿæˆã™ã‚‹ã€‚
    clip_raw.webmãŒç„¡ã‘ã‚Œã°Step0åŒæ§˜ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‹ã‚‰ã‚¯ãƒ­ãƒƒãƒ—ã™ã‚‹ã€‚
    """
    try:
        config = load_config_from_file(config_path)
    except Exception as e:
        print(f"âœ— Failed to load configuration: {e}")
        return False

    os.makedirs(config.temp_dir, exist_ok=True)
    clip_raw_path = os.path.join(config.temp_dir, "clip_raw.webm")
    clip_cropped_path = os.path.join(config.temp_dir, "clip.webm")

    # ã‚½ãƒ¼ã‚¹å‹•ç”»ã‚’æº–å‚™
    if os.path.exists(clip_raw_path):
        print(f"âœ“ Found existing raw clip: {clip_raw_path}")
        raw_video_path = clip_raw_path
    else:
        if config.auto_download:
            print("\n[Step0.5] Downloading video section (Step0 equivalent)...")
            success = download_and_clip_video(
                config.video_url,
                config.start_time,
                config.end_time,
                clip_raw_path,
                download_full=False
            )
            if not success:
                print("âœ— Failed to download video")
                return False
            raw_video_path = clip_raw_path
        else:
            if not config.webm_path or not os.path.exists(config.webm_path):
                print("âœ— clip_raw.webm not found and WEBM_PATH is invalid. Please run step0 or set WEBM_PATH.")
                return False
            raw_video_path = config.webm_path
            import shutil
            shutil.copy2(raw_video_path, clip_raw_path)

    print("\n[Step0.5] Applying crop...")
    print(f"  Top: {config.crop_top_percent}%, Bottom: {config.crop_bottom_percent}%")
    print(f"  Left: {config.crop_left_percent}%, Right: {config.crop_right_percent}%")
    cropped = apply_crop_or_copy(
        raw_video_path,
        clip_cropped_path,
        config
    )
    if not cropped:
        print("âœ— Crop failed")
        return False

    print(f"âœ“ Cropped clip saved: {clip_cropped_path}")
    print("Next: run step1/prepare/compose as needed.")
    return True


SHORT_OVERLAY_DEFAULTS = {
    'TOP_TEXT': '',
    'BOTTOM_TEXT': '',
    'TOP_TEXT_COLOR': 'white',
    'BOTTOM_TEXT_COLOR': 'white',
    'TOP_TEXT_SIZE': '72',
    'BOTTOM_TEXT_SIZE': '64',
    'TOP_TEXT_FONT': '',
    'BOTTOM_TEXT_FONT': '',
    'TOP_TEXT_BOX_COLOR': 'black@0.65',
    'BOTTOM_TEXT_BOX_COLOR': 'black@0.65',
    'TOP_TEXT_BOX_BORDER': '28',
    'BOTTOM_TEXT_BOX_BORDER': '28',
    'TOP_TEXT_BOX': '1',
    'BOTTOM_TEXT_BOX': '1',
    'TOP_TEXT_WRAP': '1',
    'BOTTOM_TEXT_WRAP': '0',
    'TOP_TEXT_WRAP_WIDTH': '14',
    'BOTTOM_TEXT_WRAP_WIDTH': '20',
    'TOP_TEXT_OFFSET_Y': '0',
    'BOTTOM_TEXT_OFFSET_Y': '0'
}


def load_short_config(config_path: str) -> dict:
    """
    ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€

    è¤‡æ•°ã‚·ãƒ¼ãƒ³å¯¾å¿œï¼š
    SCENE1_START, SCENE1_END, SCENE2_START, SCENE2_END... ã®å½¢å¼ã§è¨˜è¿°å¯èƒ½

    Args:
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        è¨­å®šè¾æ›¸ï¼ˆscenesã‚­ãƒ¼ã«è¤‡æ•°ã‚·ãƒ¼ãƒ³ã®ãƒªã‚¹ãƒˆã‚’å«ã‚€ï¼‰
    """
    config = {
        'INPUT_VIDEO': 'data/output/final.mp4',
        'OUTPUT': 'data/output/short.mp4',
        'scenes': []  # è¤‡æ•°ã‚·ãƒ¼ãƒ³ã‚’æ ¼ç´
    }
    config.update(SHORT_OVERLAY_DEFAULTS)

    if not os.path.exists(config_path):
        raise FileNotFoundError(f"Config file not found: {config_path}")

    scene_data = {}  # SCENE1_START, SCENE1_END ãªã©ã‚’ä¸€æ™‚ä¿å­˜

    with open(config_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#'):
                continue

            if '=' in line:
                key, value = line.split('=', 1)
                key = key.strip()
                value = value.strip()

                # SCENEn_START, SCENEn_END ã‚’æ¤œå‡º
                if key.startswith('SCENE') and ('_START' in key or '_END' in key):
                    scene_data[key] = value
                else:
                    config[key] = value

    # ã‚·ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†
    if scene_data:
        # SCENEã®ç•ªå·ã‚’æŠ½å‡ºã—ã¦ã‚½ãƒ¼ãƒˆ
        scene_numbers = set()
        for key in scene_data.keys():
            # SCENE1_START â†’ 1 ã‚’æŠ½å‡º
            match = re.match(r'SCENE(\d+)_', key)
            if match:
                scene_numbers.add(int(match.group(1)))

        # ç•ªå·é †ã«ã‚·ãƒ¼ãƒ³ã‚’æ§‹ç¯‰
        for num in sorted(scene_numbers):
            start_key = f'SCENE{num}_START'
            end_key = f'SCENE{num}_END'

            if start_key in scene_data and end_key in scene_data:
                config['scenes'].append({
                    'start': scene_data[start_key],
                    'end': scene_data[end_key]
                })
    else:
        # å¾“æ¥ã®å½¢å¼ï¼ˆSTART_TIME, END_TIMEï¼‰ã‚‚ã‚µãƒãƒ¼ãƒˆ
        if 'START_TIME' in config and 'END_TIME' in config:
            config['scenes'].append({
                'start': config['START_TIME'],
                'end': config['END_TIME']
            })

    return config


def _clean_str_value(value: Any, default: str = '') -> str:
    """è¨­å®šå€¤ã‚’æ–‡å­—åˆ—ã¨ã—ã¦ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    if value is None:
        return default
    return str(value).strip()


def _parse_int_value(value: Any, default: int) -> int:
    """è¨­å®šå€¤ã‚’æ•´æ•°ã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹"""
    if value is None:
        return default
    try:
        return int(float(str(value).strip()))
    except (TypeError, ValueError):
        return default


def _parse_bool_value(value: Any, default: bool) -> bool:
    """è¨­å®šå€¤ã‚’çœŸå½å€¤ã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹"""
    if value is None:
        return default
    if isinstance(value, bool):
        return value
    return str(value).strip().lower() in ('1', 'true', 'yes', 'on')


def _decode_overlay_text(value: str) -> str:
    """\\nãªã©ã®ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å®Ÿæ–‡å­—ã«å±•é–‹"""
    if not value:
        return value
    return value.replace('\\n', '\n').replace('\\r', '')


def _auto_wrap_text(text: str, max_chars: int) -> str:
    """æŒ‡å®šæ–‡å­—æ•°ã§è‡ªå‹•æ”¹è¡Œ"""
    if not text or max_chars <= 0:
        return text
    result_lines = []
    for segment in text.split('\n'):
        if not segment:
            result_lines.append('')
            continue
        line = ''
        for ch in segment:
            line += ch
            if len(line) >= max_chars:
                result_lines.append(line)
                line = ''
        if line:
            result_lines.append(line)
    return '\n'.join(result_lines)


def build_overlay_settings(config: dict) -> dict:
    """
    ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ç”¨ã®ä¸Šä¸‹ãƒ†ã‚­ã‚¹ãƒˆè¨­å®šã‚’æ§‹ç¯‰
    """
    top_text = _decode_overlay_text(_clean_str_value(config.get('TOP_TEXT')))
    bottom_text = _decode_overlay_text(_clean_str_value(config.get('BOTTOM_TEXT')))

    overlay = {
        'top_text': top_text,
        'bottom_text': bottom_text,
        'top_font': _clean_str_value(config.get('TOP_TEXT_FONT')),
        'bottom_font': _clean_str_value(config.get('BOTTOM_TEXT_FONT')),
        'top_color': _clean_str_value(config.get('TOP_TEXT_COLOR'), 'white') or 'white',
        'bottom_color': _clean_str_value(config.get('BOTTOM_TEXT_COLOR'), 'white') or 'white',
        'top_fontsize': _parse_int_value(config.get('TOP_TEXT_SIZE'), 72),
        'bottom_fontsize': _parse_int_value(config.get('BOTTOM_TEXT_SIZE'), 64),
        'top_box_color': _clean_str_value(config.get('TOP_TEXT_BOX_COLOR'), 'black@0.7') or 'black@0.7',
        'bottom_box_color': _clean_str_value(config.get('BOTTOM_TEXT_BOX_COLOR'), 'black@0.7') or 'black@0.7',
        'top_box_border': _parse_int_value(config.get('TOP_TEXT_BOX_BORDER'), 28),
        'bottom_box_border': _parse_int_value(config.get('BOTTOM_TEXT_BOX_BORDER'), 28),
        'top_wrap': _parse_bool_value(config.get('TOP_TEXT_WRAP'), True),
        'bottom_wrap': _parse_bool_value(config.get('BOTTOM_TEXT_WRAP'), False),
        'top_wrap_chars': _parse_int_value(config.get('TOP_TEXT_WRAP_WIDTH'), 14),
        'bottom_wrap_chars': _parse_int_value(config.get('BOTTOM_TEXT_WRAP_WIDTH'), 20),
        'top_offset_y': _parse_int_value(config.get('TOP_TEXT_OFFSET_Y'), 0),
        'bottom_offset_y': _parse_int_value(config.get('BOTTOM_TEXT_OFFSET_Y'), 0)
    }
    overlay['top_box'] = _parse_bool_value(
        config.get('TOP_TEXT_BOX'),
        bool(overlay['top_text'])
    )
    overlay['bottom_box'] = _parse_bool_value(
        config.get('BOTTOM_TEXT_BOX'),
        bool(overlay['bottom_text'])
    )

    if overlay['top_wrap'] and overlay['top_text']:
        overlay['top_text'] = _auto_wrap_text(overlay['top_text'], overlay['top_wrap_chars'])
    if overlay['bottom_wrap'] and overlay['bottom_text']:
        overlay['bottom_text'] = _auto_wrap_text(overlay['bottom_text'], overlay['bottom_wrap_chars'])

    overlay['top_lines'] = overlay['top_text'].split('\n') if overlay['top_text'] else []
    overlay['bottom_lines'] = overlay['bottom_text'].split('\n') if overlay['bottom_text'] else []

    overlay['top_line_colors'] = {}
    for idx, _ in enumerate(overlay['top_lines'], start=1):
        key = f'TOP_TEXT_LINE{idx}_COLOR'
        color = _clean_str_value(config.get(key))
        if color:
            overlay['top_line_colors'][idx] = color

    overlay['bottom_line_colors'] = {}
    for idx, _ in enumerate(overlay['bottom_lines'], start=1):
        key = f'BOTTOM_TEXT_LINE{idx}_COLOR'
        color = _clean_str_value(config.get(key))
        if color:
            overlay['bottom_line_colors'][idx] = color

    return overlay


def run_short_pipeline(config_path: str) -> bool:
    """
    ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆè¤‡æ•°ã‚·ãƒ¼ãƒ³å¯¾å¿œï¼‰

    Args:
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        æˆåŠŸã—ãŸå ´åˆTrue
    """
    print("=" * 60)
    print("KIRINUKI PROCESSOR - SHORT VIDEO GENERATOR")
    print("=" * 60)

    # è¨­å®šèª­ã¿è¾¼ã¿
    try:
        config = load_short_config(config_path)
        print(f"\nâœ“ Configuration loaded: {config_path}")
        print(f"  Input video: {config['INPUT_VIDEO']}")
        print(f"  Scenes: {len(config['scenes'])}")
        overlay_settings = build_overlay_settings(config)
        for i, scene in enumerate(config['scenes'], 1):
            print(f"    Scene {i}: {scene['start']} - {scene['end']}")
        print(f"  Output: {config['OUTPUT']}")
        if overlay_settings.get('top_text'):
            print(f"  Top text: {overlay_settings['top_text']}")
        if overlay_settings.get('bottom_text'):
            print(f"  Bottom text: {overlay_settings['bottom_text']}")
    except Exception as e:
        print(f"âœ— Failed to load configuration: {e}")
        return False

    # ã‚·ãƒ¼ãƒ³ãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
    if not config['scenes']:
        print(f"\nâœ— Error: No scenes defined in configuration")
        print(f"  Please define SCENE1_START, SCENE1_END, etc. in {config_path}")
        return False

    # å…¥åŠ›å‹•ç”»ã®å­˜åœ¨ç¢ºèª
    input_video = config['INPUT_VIDEO']
    if not os.path.exists(input_video):
        print(f"\nâœ— Error: Input video not found: {input_video}")
        print(f"  Please run 'python main.py compose config.txt' first to create final.mp4")
        return False

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    output_path = config['OUTPUT']
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    temp_dir = 'data/temp'
    os.makedirs(temp_dir, exist_ok=True)

    # å„ã‚·ãƒ¼ãƒ³ã‚’å€‹åˆ¥ã«ç”Ÿæˆ
    scene_files = []
    try:
        for i, scene in enumerate(config['scenes'], 1):
            scene_output = os.path.join(temp_dir, f'short_scene_{i}.mp4')
            print(f"\n[Scene {i}/{len(config['scenes'])}] Generating: {scene['start']} - {scene['end']}")

            success = generate_short_video(
                input_video,
                scene_output,
                scene['start'],
                scene['end'],
                overlay_settings=overlay_settings
            )

            if not success:
                print(f"âœ— Failed to generate scene {i}")
                return False

            scene_files.append(scene_output)

        # è¤‡æ•°ã‚·ãƒ¼ãƒ³ã‚’é€£çµ
        if len(scene_files) == 1:
            # ã‚·ãƒ¼ãƒ³ãŒ1ã¤ã ã‘ã®å ´åˆã¯ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼
            shutil.copy2(scene_files[0], output_path)
            print(f"\nâœ“ Short video created: {output_path}")
        else:
            # è¤‡æ•°ã‚·ãƒ¼ãƒ³ã‚’é€£çµ
            print(f"\n[Concatenating {len(scene_files)} scenes...]")
            success = concatenate_videos(scene_files, output_path)
            if not success:
                print("âœ— Failed to concatenate scenes")
                return False
            print(f"âœ“ Scenes concatenated: {output_path}")

    except Exception as e:
        print(f"âœ— Error generating short video: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        for scene_file in scene_files:
            if os.path.exists(scene_file):
                os.remove(scene_file)

    print("\n" + "=" * 60)
    print("âœ“ SHORT VIDEO GENERATION COMPLETED!")
    print("=" * 60)
    print(f"\nOutput: {output_path}")
    print(f"Total scenes: {len(config['scenes'])}")
    print()

    return True


def run_single_step(step_num: float, args: argparse.Namespace) -> bool:
    """
    å˜ä¸€ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œ

    Args:
        step_num: ã‚¹ãƒ†ãƒƒãƒ—ç•ªå·ï¼ˆ1.5ãªã©ã®å°æ•°ã‚‚å¯ï¼‰
        args: ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°

    Returns:
        æˆåŠŸã—ãŸã‹ã©ã†ã‹
    """
    print(f"\n[Step {step_num}] Running single step...")

    if step_num == 0:
        # å‹•ç”»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»åˆ‡ã‚ŠæŠœã
        success = download_and_clip_video(
            args.url,
            args.start,
            args.end,
            args.output,
            download_full=args.full if hasattr(args, 'full') else False
        )
        return success

    elif step_num == 0.5:
        # ã‚¯ãƒ­ãƒƒãƒ—ã®ã¿ï¼ˆconfigã‚’èª­ã¿ã€clip_rawâ†’clipã«é©ç”¨ï¼‰
        success = run_crop_step(args.config)
        return success

    elif step_num == 1:
        # Whisperå­—å¹•ç”Ÿæˆ
        success = generate_subtitles_with_whisper(
            args.input,
            args.output,
            model_size=args.model if hasattr(args, 'model') else "large",
            language=args.language if hasattr(args, 'language') else "ja"
        )
        return success

    elif step_num == 1.5:
        # å­—å¹•ä¿®æ­£
        method = args.method if hasattr(args, 'method') else "rule-based"

        if method == "ai":
            # AIãƒ™ãƒ¼ã‚¹ã§ä¿®æ­£
            from kirinuki_processor.steps.step1_5_fix_subtitles_ai import fix_subtitle_file_ai
            success = fix_subtitle_file_ai(
                args.input,
                args.output,
                model=args.model if hasattr(args, 'model') else "llama-3.3-70b-versatile"
            )
        else:
            # ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ä¿®æ­£
            success = fix_subtitle_file(
                args.input,
                args.output,
                model="rule-based"
            )
        return success

    elif step_num == 2:
        # ãƒãƒ£ãƒƒãƒˆå–å¾—
        success = fetch_chat(args.url, args.output)
        return success

    elif step_num == 3:
        # ãƒãƒ£ãƒƒãƒˆæŠ½å‡º
        count = load_and_extract_chat(
            args.input,
            args.output,
            args.start,
            args.end,
            delay_seconds=args.delay if hasattr(args, 'delay') else 0.0
        )
        return count > 0

    elif step_num == 4:
        # ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”Ÿæˆ
        config = OverlayConfig()
        count = generate_overlay_from_file(
            args.input,
            args.output,
            config
        )
        return count > 0

    elif step_num == 5:
        # å‹•ç”»åˆæˆ
        success = compose_video(
            args.video,
            args.output,
            subtitle_path=args.subtitle if hasattr(args, 'subtitle') else None,
            overlay_path=args.overlay if hasattr(args, 'overlay') else None
        )
        return success

    elif step_num == 6:
        # YouTubeèª¬æ˜æ¬„ç”Ÿæˆ
        success = generate_youtube_description(
            args.input,
            args.output,
            prompt_template_path=args.prompt if hasattr(args, 'prompt') else "data/input/setumei",
            model=args.model if hasattr(args, 'model') else "llama-3.3-70b-versatile"
        )
        return success

    else:
        print(f"Unknown step: {step_num}")
        return False


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description="KIRINUKI Processor - ã²ã‚ã‚†ãå‹•ç”»åˆ‡ã‚ŠæŠœãå‡¦ç†ãƒ„ãƒ¼ãƒ«"
    )

    subparsers = parser.add_subparsers(dest="command", help="Commands")

    # ç´ ææº–å‚™ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    prepare_parser = subparsers.add_parser("prepare", help="Prepare materials (download, subtitles, chat) - stops before composing video")
    prepare_parser.add_argument("config", help="Configuration file path")

    # å­—å¹•å†ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    resub_parser = subparsers.add_parser("resub", help="Regenerate subtitles only (useful when Whisper subtitles have issues)")
    resub_parser.add_argument("config", help="Configuration file path")

    # ãƒãƒ£ãƒƒãƒˆå†ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    rechat_parser = subparsers.add_parser("rechat", help="Regenerate chat overlay only (useful for adjusting CHAT_DELAY_SECONDS)")
    rechat_parser.add_argument("config", help="Configuration file path")

    # å‹•ç”»åˆæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    compose_parser = subparsers.add_parser("compose", help="Compose final video using prepared materials")
    compose_parser.add_argument("config", help="Configuration file path")

    # å‡ºåŠ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    output_parser = subparsers.add_parser("output", help="Copy final.mp4, description.txt, and config to a titled folder")
    output_parser.add_argument("config", help="Configuration file path")

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    clear_parser = subparsers.add_parser("clear", help="Delete temporary files to prepare for next video")
    clear_parser.add_argument("config", help="Configuration file path")
    clear_parser.add_argument("--keep-videos", action="store_true", help="Keep video files (clip*.webm) and only delete subtitles/chat files")

    # ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œï¼ˆprepareâ†’composeã®é †ã«å…¨ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œï¼‰
    pipeline_parser = subparsers.add_parser("run", help="Run full pipeline (prepare then compose)")
    pipeline_parser.add_argument("config", help="Configuration file path")

    # ã‚µãƒ³ãƒ—ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    sample_parser = subparsers.add_parser("init", help="Create sample config file")
    sample_parser.add_argument(
        "-o", "--output",
        default="config.txt",
        help="Output path for sample config (default: config.txt)"
    )

    # ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    short_parser = subparsers.add_parser("short", help="Generate vertical short video from clip.webm or concatenated.webm")
    short_parser.add_argument("config", help="Short config file path (e.g., short_config.txt)")

    # å€‹åˆ¥ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œç”¨ã®ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰
    # Step 0
    step0_parser = subparsers.add_parser("step0", help="Download and clip video")
    step0_parser.add_argument("url", help="YouTube video URL")
    step0_parser.add_argument("-s", "--start", required=True, help="Start time (hh:mm:ss)")
    step0_parser.add_argument("-e", "--end", help="End time (hh:mm:ss)")
    step0_parser.add_argument("-o", "--output", required=True, help="Output video file")
    step0_parser.add_argument("--full", action="store_true", help="Download full video first (slower but more reliable)")

    # Step 0.5 (ã‚¯ãƒ­ãƒƒãƒ—ã®ã¿)
    step0_5_parser = subparsers.add_parser("step0.5", help="Apply crop to clip_raw.webm (download if missing) to create clip.webm")
    step0_5_parser.add_argument("config", help="Configuration file path")

    # Step 1 (Whisperå­—å¹•ç”Ÿæˆ)
    step1_parser = subparsers.add_parser("step1", help="Generate subtitles with Whisper")
    step1_parser.add_argument("-i", "--input", required=True, help="Input video file")
    step1_parser.add_argument("-o", "--output", required=True, help="Output SRT file")
    step1_parser.add_argument("-m", "--model", default="large", choices=["tiny", "base", "small", "medium", "large"], help="Whisper model size (default: large)")
    step1_parser.add_argument("-l", "--language", default="ja", help="Language code (default: ja)")

    # Step 1.5 (å­—å¹•ä¿®æ­£)
    step1_5_parser = subparsers.add_parser("step1.5", help="Fix subtitles")
    step1_5_parser.add_argument("-i", "--input", required=True, help="Input SRT file")
    step1_5_parser.add_argument("-o", "--output", required=True, help="Output SRT file")
    step1_5_parser.add_argument("--method", choices=["rule-based", "ai"], default="rule-based", help="Correction method: rule-based (fast, safe) or ai (smarter, requires API)")
    step1_5_parser.add_argument("-m", "--model", default="llama-3.3-70b-versatile", help="Groq model name for AI method (default: llama-3.3-70b-versatile)")

    # Step 2 (ãƒãƒ£ãƒƒãƒˆå–å¾—)
    step2_parser = subparsers.add_parser("step2", help="Fetch live chat")
    step2_parser.add_argument("url", help="YouTube video URL")
    step2_parser.add_argument("-o", "--output", required=True, help="Output JSON file")

    # Step 3 (ãƒãƒ£ãƒƒãƒˆæŠ½å‡º)
    step3_parser = subparsers.add_parser("step3", help="Extract chat")
    step3_parser.add_argument("-i", "--input", required=True, help="Input JSON file")
    step3_parser.add_argument("-o", "--output", required=True, help="Output JSON file")
    step3_parser.add_argument("-s", "--start", required=True, help="Start time (hh:mm:ss)")
    step3_parser.add_argument("-e", "--end", help="End time (hh:mm:ss)")
    step3_parser.add_argument("-d", "--delay", type=float, default=0.0, help="Chat display delay in seconds (default: 0)")

    # Step 4 (ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ç”Ÿæˆ)
    step4_parser = subparsers.add_parser("step4", help="Generate overlay")
    step4_parser.add_argument("-i", "--input", required=True, help="Input JSON file")
    step4_parser.add_argument("-o", "--output", required=True, help="Output ASS file")

    # Step 5 (å‹•ç”»åˆæˆ)
    step5_parser = subparsers.add_parser("step5", help="Compose video")
    step5_parser.add_argument("-v", "--video", required=True, help="Input video file")
    step5_parser.add_argument("-o", "--output", required=True, help="Output video file")
    step5_parser.add_argument("-s", "--subtitle", help="Subtitle file (SRT)")
    step5_parser.add_argument("-c", "--overlay", help="Chat overlay file (ASS)")

    # Step 6 (YouTubeèª¬æ˜æ¬„ç”Ÿæˆ)
    step6_parser = subparsers.add_parser("step6", help="Generate YouTube description")
    step6_parser.add_argument("-i", "--input", required=True, help="Input SRT file")
    step6_parser.add_argument("-o", "--output", required=True, help="Output text file")
    step6_parser.add_argument("-p", "--prompt", default="data/input/setumei", help="Prompt template file (default: data/input/setumei)")
    step6_parser.add_argument("-m", "--model", default="llama-3.3-70b-versatile", help="Groq model name (default: llama-3.3-70b-versatile)")

    args = parser.parse_args()

    # ã‚³ãƒãƒ³ãƒ‰ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆ
    if not args.command:
        parser.print_help()
        return 1

    # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ
    try:
        if args.command == "prepare":
            success = run_prepare_pipeline(args.config)
            return 0 if success else 1

        elif args.command == "resub":
            success = run_resub_pipeline(args.config)
            return 0 if success else 1

        elif args.command == "rechat":
            success = run_rechat_pipeline(args.config)
            return 0 if success else 1

        elif args.command == "compose":
            success = run_compose_pipeline(args.config)
            return 0 if success else 1

        elif args.command == "output":
            success = run_output_pipeline(args.config)
            return 0 if success else 1

        elif args.command == "clear":
            success = run_clear_pipeline(args.config, keep_videos=args.keep_videos)
            return 0 if success else 1

        elif args.command == "run":
            success = run_full_pipeline(args.config, [])
            return 0 if success else 1

        elif args.command == "init":
            create_sample_config(args.output)
            return 0

        elif args.command == "short":
            success = run_short_pipeline(args.config)
            return 0 if success else 1

        elif args.command == "step0.5":
            success = run_crop_step(args.config)
            return 0 if success else 1

        elif args.command.startswith("step"):
            step_str = args.command[4:]
            step_num = float(step_str) if '.' in step_str else int(step_str)
            success = run_single_step(step_num, args)
            return 0 if success else 1

        else:
            print(f"Unknown command: {args.command}")
            return 1

    except KeyboardInterrupt:
        print("\n\nInterrupted by user")
        return 1
    except Exception as e:
        print(f"\nâœ— Error: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
